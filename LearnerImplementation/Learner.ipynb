{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dataloader:\n",
    "    \n",
    "    def __init__(self, train_dataset=None, valid_dataset=None, batch_size=256, shuffle=True):\n",
    "        self.tds = train_dataset\n",
    "        self.vds = valid_dataset\n",
    "        self.bs = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def get_dl_dims(self):\n",
    "        x, y = self.tds[0]\n",
    "        return len(x) \n",
    "    \n",
    "    # create training model (personal or resent18 for example)\n",
    "    def create_linear_model(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.get_dl_dims(), 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30,1)\n",
    "        )\n",
    "    \n",
    "    def get_train_dl(self):\n",
    "        return DataLoader(self.tds, self.bs, self.shuffle)\n",
    "    \n",
    "    def get_valid_dl(self):\n",
    "        return DataLoader(self.vds, self.bs, self.shuffle)\n",
    "    \n",
    "    def get_dataloaders(self):\n",
    "        return (self.get_train_dl(), self.get_valid_dl())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): \n",
    "        self.params, self.lr = list(params), lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_learner:\n",
    "    \n",
    "    def __init__(self, dls=None, training_model=None, optimization_function=None, \n",
    "                 loss_function=None, lr=1e-4, metrics=None):\n",
    "        # Initialize all variables\n",
    "        self.train_dl, self.valid_dl = dls\n",
    "        self.model = training_model\n",
    "        self.opt_func = optimization_function\n",
    "        self.loss_func = loss_function \n",
    "        self.lr = lr\n",
    "        self.metrics = self.batch_accuracy if metrics == 'accuracy' else metrics\n",
    "        \n",
    "        self.output_cols = ['epoch', 'train_loss', 'valid_loss', 'metrics']\n",
    "        self.output_rows = []\n",
    "        \n",
    "        self._epoch = 0\n",
    "        self._tloss = 0.\n",
    "        self._vloss = 0.\n",
    "        self._met = 0.\n",
    "        \n",
    "    def add_data(self):\n",
    "        self.output_rows.append([self._epoch, self._tloss, self._vloss, self._met])\n",
    "        \n",
    "    def show_output(self):\n",
    "        d = pd.DataFrame(columns=self.output_cols, data=self.output_rows)\n",
    "        return d.style.hide_index()\n",
    "        \n",
    "    # do single training loop\n",
    "    def train_epoch(self, model):\n",
    "        for xb, yb in self.train_dl:\n",
    "            self.calc_gradient(xb, yb, model)\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "        for xb, yb in self.valid_dl:\n",
    "            self._log_validation_loss(xb, yb, model)\n",
    "            \n",
    "    # do actual training \n",
    "    def train_model(self, model, epochs):\n",
    "        m = model if model else self.model\n",
    "        if epochs > 0:\n",
    "            self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "            for i in range(epochs):\n",
    "                self._epoch = i\n",
    "                self.train_epoch(m)\n",
    "                self._met = self.validate_epoch(m)\n",
    "                self.add_data()\n",
    "    \n",
    "    def validate_epoch(self, model):\n",
    "        accs = [self.metrics(model(xb), yb) for xb, yb in self.valid_dl]\n",
    "        self._met = round(torch.stack(accs).mean().item(), 4)\n",
    "        return self._met\n",
    "    \n",
    "    def _log_validation_loss(self, xb, yb, model):\n",
    "        preds = model(xb)\n",
    "        loss = self.loss_func(preds, yb)\n",
    "        self._vloss = round(loss.item(), 4)\n",
    "        return self._vloss\n",
    "    \n",
    "    def calc_gradient(self, xb, yb, model):\n",
    "        preds = model(xb)\n",
    "        loss = self.loss_func(preds, yb)\n",
    "        self._tloss = round(loss.item(), 4)\n",
    "        loss.backward()\n",
    "    \n",
    "    def batch_accuracy(self, xb, yb):\n",
    "        preds = xb.sigmoid()\n",
    "        correct = (preds>0.5) == yb\n",
    "        return correct.float().mean()\n",
    "    \n",
    "    def fit(self, epochs, learning_rate=0):\n",
    "        if (learning_rate > 0):\n",
    "            self.lr = learning_rate\n",
    "        self.train_model(self.model, epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets setup\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset tensors\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "\n",
    "d1, d2 = seven_tensors[0].shape # get dimension sizes\n",
    "dsqr = d1 * d2 # dimention size\n",
    "\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, dsqr)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "\n",
    "train_ds = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset setup\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, dsqr)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "\n",
    "valid_ds = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from datasets\n",
    "dls = my_dataloader(train_ds, valid_ds)\n",
    "dataloaders = dls.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get linear training model\n",
    "training_model = dls.create_linear_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the loss function\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets == 1, 1 - predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create learner\n",
    "learn = my_learner(dataloaders, training_model, optimization_function=SGD, \n",
    "                   loss_function=mnist_loss, lr=0.01, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the learner\n",
    "learn.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
